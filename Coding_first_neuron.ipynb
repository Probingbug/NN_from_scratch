{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMC5QyclVOouo0Lq6ZWhwo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Probingbug/NN_from_scratch/blob/main/Coding_first_neuron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhSPMa5eFXk1",
        "outputId": "1d1bfdb2-4295-423d-ca04-0c6af20c2366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4999999999999998\n"
          ]
        }
      ],
      "source": [
        "inputs = [1,2,3,2.5]\n",
        "weights = [0.5,0.25,-0.4,0.6]\n",
        "bias = 0.2\n",
        "\n",
        "output = inputs[0]*weights[0]+ inputs[1]*weights[1]+inputs[2]*weights[2] + inputs[3]* weights[3]+bias\n",
        "\n",
        "print (output)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#layers of neurons\n",
        "\n",
        "inputs = [1,2,3,2.5]\n",
        "weights = [[0.5,0.25,-0.4,0.6], #weights are stored in the manner of weights coming from each input to a single neuron\n",
        "           [.4,.5,-.3,-0.6], # neuron 2\n",
        "           [0.7,0.65,0.87,0.98] # neuron 3\n",
        "          ]\n",
        "\n",
        "biases=[0.2,0.3,0.4]\n",
        "\n",
        "outputs = []\n",
        "\n",
        "for i in range(len(weights)):\n",
        "    output = inputs[0]*weights[i][0]+ inputs[1]*weights[i][1]+inputs[2]*weights[i][2] + inputs[3]* weights[i][3]+biases[i]\n",
        "    outputs.append(output)\n",
        "    print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDT_S2aLGFBg",
        "outputId": "ff1b34cd-27c9-4801-eb47-957364135b83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.4999999999999998\n",
            "-0.7\n",
            "7.46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using numpy\n",
        "\n",
        "import numpy as np\n",
        "import nnfs # Import nnfs to ensure the modified np.dot is used.\n",
        "\n",
        "inputs = [1,2,3,2.5]\n",
        "weights = [[0.5,0.25,-0.4,0.6], #weights are stored in the manner of weights coming from each input to a single neuron\n",
        "           [.4,.5,-.3,-0.6], # neuron 2\n",
        "           [0.7,0.65,0.87,0.98] # neuron 3\n",
        "          ]\n",
        "biases=[0.2,0.3,0.4]\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "inputs = np.array(inputs)\n",
        "weights = np.array(weights)\n",
        "biases = np.array(biases)\n",
        "\n",
        "output = np.dot(inputs,np.transpose(weights))+ biases\n",
        "print (output)"
      ],
      "metadata": {
        "id": "NwM3FKpNIXFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9009d65a-ee26-422c-ae7b-34e5cac9bd3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 1.5  -0.7   7.46]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "for batch of inputs"
      ],
      "metadata": {
        "id": "5vAbmupKxjtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs= [\n",
        "    [1,2,3,4], #batch one\n",
        "    [5,6,7,8], #batch 2\n",
        "    [9,8,7,6]  #batch 3\n",
        "      ]\n",
        "\n",
        "weights=[\n",
        "    [.1,.2,.3,.4],#neuron 1 weights\n",
        "     [.5,.6,.7,.8], #nueron 2\n",
        "      [.9,.8,.7,.6] #neuron 3\n",
        "]\n",
        "\n",
        "biases=[[0.1,0.2,0.3],\n",
        "[0.1,0.2,0.3],\n",
        "[0.1,0.2,0.3]]\n",
        "\n",
        "# Convert inputs and weights to numpy arrays\n",
        "inputs = np.array(inputs)\n",
        "weights = np.array(weights)\n",
        "\n",
        "output = np.dot(inputs,np.transpose(weights))+ np.array(biases)\n",
        "print (output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vbt5i202xmpA",
        "outputId": "f31f82f8-6176-49f7-b30d-1444ed594b99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.1  7.2  7.3]\n",
            " [ 7.1 17.6 19.3]\n",
            " [ 7.1 19.2 23.3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ADDING MULTIPLE LAYERS**"
      ],
      "metadata": {
        "id": "qSV9NKQG4RfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs1 =[[1,2,3,4],[5,6,7,8],[2,3,6,7]]\n",
        "weights1= [[.1,.2,.3,.4],[.5,.6,.7,.8],[.9,0,.2,.3]]\n",
        "\n",
        "biases1 = [.2,.3,.5]\n",
        "\n",
        "weights2 = [\n",
        "              [0.2,0.4,0.5],\n",
        "              [.4,-.9,-.5],\n",
        "              [.6,.7,.8]\n",
        "            ]\n",
        "biases2= [.2,.3,.5]\n",
        "\n",
        "# convert lists into arrays\n",
        "\n",
        "inputs1 = np.array(inputs1)\n",
        "weights1 = np.array(weights1)\n",
        "biases1 = np.array(biases1)\n",
        "weights2 = np.array(weights2)\n",
        "biases2 = np.array(biases2)\n",
        "\n",
        "\n",
        "output1 = np.dot(inputs1, weights1.T) +biases1\n",
        "output2 = np.dot(output1, weights2.T) +biases2\n",
        "\n",
        "print (output1)\n",
        "print (output2)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23XMGXLR4RNP",
        "outputId": "ee6bc364-8e6e-46c1-d7d5-0c82dd8a2402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 3.2  7.3  3.2]\n",
            " [ 7.2 17.7  8.8]\n",
            " [ 5.6 12.9  5.6]]\n",
            "[[  5.36  -6.59  10.09]\n",
            " [ 13.12 -17.15  24.25]\n",
            " [  9.28 -11.87  17.37]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CLASSIFYING SPIRAL DATASET USING NN**"
      ],
      "metadata": {
        "id": "90-UUKen-0nX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "class Layer_Dense:\n",
        "  #Layer initialzation\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  #forward pass\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    self.output = np.dot(inputs,self.weights) + self.biases\n",
        "\n",
        "\n",
        "# create dataset\n",
        "\n",
        "X,y = spiral_data(samples = 300,classes = 3)\n",
        "\n",
        "# create the dense layer with 2 input features and 3 output values\n",
        "\n",
        "dense_1= Layer_Dense(2,3)\n",
        "\n",
        "#perform forward pass of our training data through this layer\n",
        "\n",
        "dense_1.forward(X)\n",
        "\n",
        "#Let's see the output of the first few samples\n",
        "\n",
        "print(dense_1.output[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXpWmS5L-8Pf",
        "outputId": "0f4c5870-d63d-4e8e-d463-561cb108336e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [-5.1206993e-05 -3.3002120e-04  6.2150566e-04]\n",
            " [-4.0815637e-04 -7.2520698e-04  1.1652119e-03]\n",
            " [-1.3122181e-03 -9.3719346e-04  9.7353902e-04]\n",
            " [-1.5902807e-03 -1.3504610e-03  1.6067076e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dense_1.output.shape)\n",
        "print(len(dense_1.output))\n",
        "print(dense_1.output[:5])  # show first 5 entries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbeJJHEwTw8Z",
        "outputId": "0723d40a-afa7-498a-a91f-41a08abf75ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(900, 3)\n",
            "900\n",
            "[[ 0.0000000e+00  0.0000000e+00  0.0000000e+00]\n",
            " [-5.1206993e-05 -3.3002120e-04  6.2150566e-04]\n",
            " [-4.0815637e-04 -7.2520698e-04  1.1652119e-03]\n",
            " [-1.3122181e-03 -9.3719346e-04  9.7353902e-04]\n",
            " [-1.5902807e-03 -1.3504610e-03  1.6067076e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce506768",
        "outputId": "f7b1f34d-d870-4e09-914a-4c783d41e73a"
      },
      "source": [
        "!pip install nnfs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nnfs in /usr/local/lib/python3.11/dist-packages (0.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from nnfs) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0096b1a",
        "outputId": "0a4ebbc0-5590-4603-fcf7-f6e3e6393876"
      },
      "source": [
        "import numpy as np\n",
        "import nnfs\n",
        "from nnfs.datasets import spiral_data\n",
        "\n",
        "nnfs.init()\n",
        "\n",
        "class Layer_Dense:\n",
        "  #Layer initialzation\n",
        "  def __init__(self,n_inputs,n_neurons):\n",
        "    self.weights = 0.10 * np.random.randn(n_inputs,n_neurons)\n",
        "    self.biases = np.zeros((1,n_neurons))\n",
        "\n",
        "  #forward pass\n",
        "\n",
        "  def forward(self,inputs):\n",
        "    self.output = np.dot(inputs,self.weights) + self.biases\n",
        "\n",
        "\n",
        "# create dataset\n",
        "\n",
        "X,y = spiral_data(samples = 300,classes = 3)\n",
        "\n",
        "# create the dense layer with 2 input features and 3 output values\n",
        "\n",
        "dense_1= Layer_Dense(2,3)\n",
        "\n",
        "#perform forward pass of our training data through this layer\n",
        "\n",
        "dense_1.forward(X)\n",
        "\n",
        "#Let's see the output of the first few samples\n",
        "\n",
        "print(dense_1.output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            " [-5.12069928e-05 -3.30021197e-04  6.21505664e-04]\n",
            " [-4.08156367e-04 -7.25206977e-04  1.16521190e-03]\n",
            " ...\n",
            " [ 1.00714847e-01  1.06049426e-01 -1.42564029e-01]\n",
            " [ 4.08301316e-02 -7.35828429e-02  1.74011499e-01]\n",
            " [ 1.45113930e-01  7.22821429e-02 -4.53039408e-02]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(dense_1.output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVTigCuaTVov",
        "outputId": "7c61ae0a-d440-48a2-df2e-409bfc230415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTIVATION FUNCTIONS**"
      ],
      "metadata": {
        "id": "5RlvsLZNGYo2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [\n",
        "          [1,2,3,4],\n",
        "          [15,36,57,8],\n",
        "          [9.3,10.4,1,12]\n",
        "          ]\n",
        "\n",
        "#get the unnormalized probability form of output\n",
        "\n",
        "exp_values = np.exp(inputs-np.max(inputs,axis=1,keepdims=True))\n",
        "\n",
        "#get actual probability form\n",
        "\n",
        "probabilities = exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
        "\n",
        "print(probabilities)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMHp37iWGepf",
        "outputId": "4085b19e-8351-4a11-9ef5-d76445188a4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.20586033e-02 8.71443187e-02 2.36882818e-01 6.43914260e-01]\n",
            " [5.74952226e-19 7.58256042e-10 9.99999999e-01 5.24288566e-22]\n",
            " [5.29544723e-02 1.59084026e-01 1.31600774e-05 7.87948341e-01]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(probabilities,axis =1 , keepdims=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtV--nbVHtgH",
        "outputId": "53dcd437-e195-45c4-8618-d5b0e5df3652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [1.],\n",
              "       [1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ACTIVATION FUNCTION IN THE FORM OF OOPS**"
      ],
      "metadata": {
        "id": "mR9S9YSrH5f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_softmax :\n",
        "  def forward(self,inputs):\n",
        "    exp_values = np.exp(inputs- np.max(inputs,axis=1,keepdims = True))\n",
        "    probablities = exp_values/np.sum(exp_values,axis=1,keepdims=True)\n",
        "    self.output= probablities\n"
      ],
      "metadata": {
        "id": "JGXoPOrFH_BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation_ReLU:\n",
        "  def forward(self,inputs):\n",
        "    self.output = np.maximum(0,inputs)"
      ],
      "metadata": {
        "id": "9ZiZ_o-2LSNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LET'S MAKE IT WORK ON A DATASET**"
      ],
      "metadata": {
        "id": "oOgnPYGbIuvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#create a dataset\n",
        "X,y = spiral_data(samples = 100, classes = 3)\n",
        "\n",
        "print(len(X))\n",
        "\n",
        "# Create a dense layer with two input features and 3 output values\n",
        "Dense1 = Layer_Dense(2,3)\n",
        "Dense1.forward(X)\n",
        "\n",
        "# ReLU activation function\n",
        "activation1 = Activation_ReLU()\n",
        "activation1.forward(Dense1.output)\n",
        "\n",
        "print(activation1.output.shape)\n",
        "\n",
        "# Create second dense layer with 3 inputs and 3 outputs\n",
        "Dense2  = Layer_Dense(3,2)\n",
        "Dense2.forward(activation1.output)\n",
        "\n",
        "Activation2= Activation_softmax()\n",
        "Activation2.forward(Dense2.output)\n",
        "\n",
        "print(Activation2.output.shape)\n",
        "\n",
        "# make a forwarf pass of our training data through this layer\n",
        "\n",
        "\n",
        "# make forward pass through activation function\n",
        "# it takes output from the neurons and pass it through the ReLU Activation function\n",
        "\n",
        "\n",
        "##similarly for second layer\n",
        "\n",
        "\n",
        "\n",
        "print(Activation2.output[:5])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW7wv6cZJNGB",
        "outputId": "a4ce6837-5c72-4fd5-8df9-dfab7e1fa665"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n",
            "(300, 3)\n",
            "(300, 2)\n",
            "[[0.5        0.5       ]\n",
            " [0.49998558 0.5000144 ]\n",
            " [0.49997503 0.500025  ]\n",
            " [0.49996287 0.50003713]\n",
            " [0.49993548 0.50006455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(Activation2.output))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUWw6we0OdFF",
        "outputId": "5e4d1fd4-541d-4f64-8a69-53a3df0ab47f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Activation2.output)  # âžœ 300\n",
        "Activation2.output.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_Xi9qWnk1K7",
        "outputId": "a59fcf5a-713f-4aa5-a68c-43e4c63cda45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOW LET'S FIND THE LOSS OF THIS NETWORK**"
      ],
      "metadata": {
        "id": "l-m90Wkg5VqK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all I store the maximum probability from ech batch of input."
      ],
      "metadata": {
        "id": "DUrxwCBs6Lvr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_target = np.max(Activation2.output,axis=1,keepdims=True)\n",
        "print(class_target[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTQAvbAN5c0I",
        "outputId": "a96b0080-3f4d-4ead-bf48-70c74c22cd78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.5       ]\n",
            " [0.5000144 ]\n",
            " [0.500025  ]\n",
            " [0.50003713]\n",
            " [0.50006455]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, pass it to the formula of categorical cross entropy loss. -(log(p))"
      ],
      "metadata": {
        "id": "xIvUJK8L6T7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c=-np.log(class_target)\n",
        "print(c[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RgR-xolZ6iUv",
        "outputId": "4c2d843c-91b0-44ae-9c51-a2a1d5277ab0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.6931472 ]\n",
            " [0.69311833]\n",
            " [0.69309723]\n",
            " [0.6930729 ]\n",
            " [0.6930181 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUY05hikErcz",
        "outputId": "5bfd3040-e229-4051-c050-8ef0b8f6a720"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float32(0.6923797)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "there is one more method of doing the same thing.\n",
        "Take the one hot encoding for each batch then take the element wise multiplication of that onehot encoding with the actual probability matrix.\n",
        "Then it is going to give you the only one element which is having highest probability as one hot encoing is one for the highest value and zero for others.\n",
        "\n",
        "then simply pass it through the sum function then -np.log(probability) value..\n",
        "then take the mean of that value . mean error will be there as the result."
      ],
      "metadata": {
        "id": "QQu9AHwiFAuI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Gbr8rzZYFFU5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}